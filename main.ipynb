{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: YOLOX_DATADIR=/efs/data/coco_data/\n"
     ]
    }
   ],
   "source": [
    "!export YOLOX_DATADIR=/efs/data/coco_data/\n",
    "%env YOLOX_DATADIR=/efs/data/coco_data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/efs/data/coco_data/\n"
     ]
    }
   ],
   "source": [
    "!echo $YOLOX_DATADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"yolox-s\"\n",
    "num_accelerators = 1\n",
    "total_batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env_var_options = \"NEURON_RT_ASYNC_EXEC_MAX_INFLIGHT_REQUESTS=3  \" + \\\n",
    "    \"NEURON_CC_FLAGS=\\'--cache_dir=./compiler_cache --model-type=cnn-training\\'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compile model\n",
      "Running command: \n",
      "NEURON_RT_ASYNC_EXEC_MAX_INFLIGHT_REQUESTS=3  NEURON_CC_FLAGS='--cache_dir=./compiler_cache --model-type=cnn-training' neuron_parallel_compile python -m    yolox.tools.train     -n yolox-s     -d 1     -b 2     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-27 22:04:54.000003:  140122  INFO ||NEURON_PARALLEL_COMPILE||: Removing existing workdir /tmp/ubuntu/parallel_compile_workdir\n",
      "2024-08-27 22:04:54.000004:  140122  INFO ||NEURON_PARALLEL_COMPILE||: Running trial run (add option to terminate trial run early; also ignore trial run's generated outputs, i.e. loss, checkpoints)\n",
      "2024-08-27 22:04:54.000004:  140122  INFO ||NEURON_PARALLEL_COMPILE||: Running cmd: ['python', '-m', 'yolox.tools.train', '-n', 'yolox-s', '-d', '1', '-b', '2']\n",
      "/bin/sh: 1: nvidia-smi: not found\n",
      "2024-08-27 22:05:05 | INFO     | yolox.core.trainer:140 - args: Namespace(experiment_name='yolox_s', name='yolox-s', dist_backend='nccl', dist_url=None, batch_size=2, devices=1, exp_file=None, resume=False, ckpt=None, start_epoch=None, num_machines=1, machine_rank=0, fp16=False, cache=None, occupy=False, logger='tensorboard', opts=[])\n",
      "2024-08-27 22:05:05 | INFO     | yolox.core.trainer:141 - exp value:\n",
      "���═���══��══���══���══��══�����═�����═══��══�����══����═�����══�����═�����══��══���\n",
      "��� keys              │ values                     ��\n",
      "╞═�����══���══������══�����══���══�����═�����══���══�����══�����══�����═�����══��══���╡\n",
      "│ seed              �� None                       │\n",
      "├─����─���─��──�����──�����──�����┼─��──���──���──�����──�����──�����──���──�����─┤\n",
      "│ output_dir        │ './YOLOX_outputs'          │\n",
      "├�����──�����──���──����─�����──��┼─�����──�����──�����──����─�����──��──�������─�����\n",
      "�� print_interval    │ 10                         ���\n",
      "�����──�����──��──�����──�����─���─┼�����──�����──���───�����──�����──�����─������──�����\n",
      "�� eval_interval     ��� 10                         │\n",
      "├─�����─������──�����──�����──�����─�������─���─�����─�����──�����──�����──����─�����──�����\n",
      "�� dataset           │ None                       ���\n",
      "������──�����───����─�����─�����──�����─��������──�����──�����─��──�����──�����──�����─�����\n",
      "�� num_classes       │ 80                         ��\n",
      "��──�����──�����──�����──�����──�����──�����──��──�����──���──�����──���──�����──�����\n",
      "�� depth             ��� 0.33                       │\n",
      "├─�����──�����──�����──�����─�����─┼�����──�����──�����──�����──��──�����─�����──�����┤\n",
      "│ width             ��� 0.5                        ��\n",
      "��──�����──�����──�����──�����──�����──�����──���──�����──�����──���──�����──�����──���\n",
      "�� act               │ 'silu'                     ���\n",
      "��──�����──���──�����──�����──���─┼�����──�����──���──�����───�����──�����─��──�����┤\n",
      "│ data_num_workers  �� 4                          │\n",
      "├─��──�����──���──�����──�����──����─�����──�����──�����──�����──�����─��������──���─���\n",
      "��� input_size        │ (640, 640)                 │\n",
      "├�����──���───�����──�����──�����─┼�����──����──�����──�����──�����──�����──�����──���\n",
      "�� multiscale_range  ��� 5                          ��\n",
      "├─�����─��─���───�����─���──�����─┼���──�����─�����──�����──��──�����──���───��──���\n",
      "��� data_dir          │ None                       ���\n",
      "�����──���─���───��──�����─������──�����──�����──�����─�����──�����──���───��──�����─���\n",
      "│ train_ann         │ 'instances_train2017.json' │\n",
      "├���──�����─������──�����─������──���─┼─�����──���──�����──�����─������───���───��──���┤\n",
      "│ val_ann           ��� 'instances_val2017.json'   │\n",
      "├─�����──�����──��──�����─�����──���──���──��───���──��──��─�����─���──��──��─┤\n",
      "│ test_ann          �� 'instances_test2017.json'  │\n",
      "├─�����──����──�����──��───��─┼�����──�����──���──�����──���─�����������───��─���─┤\n",
      "│ mosaic_prob       �� 1.0                        │\n",
      "├─����──�����─������──�����──�����─┼����─�����──�����─�����──�����──��──�����──���──┤\n",
      "│ mixup_prob        �� 1.0                        ���\n",
      "�����─������──�����──�����──�����──�����──�����──�����──�����──����──�����──����──����┤\n",
      "│ hsv_prob          ��� 1.0                        ��\n",
      "��──���──��──�����──���───�����─┼�����──��──�����──������───���───�����──�����──��\n",
      "��� flip_prob         │ 0.5                        │\n",
      "������──�����──�����──���──��──�����┼─�����──�����──��──�����──�����──�����──�����──���\n",
      "��� degrees           │ 10.0                       │\n",
      "├�����──�����──�����──��─��────���──��──�������──�����──�����──�����──�����──�����┤\n",
      "│ translate         ��� 0.1                        ���\n",
      "����─�����──�����──�����──�����──��┼─�����──���──�����──�����──�����─������──�����──�����\n",
      "│ mosaic_scale      ��� (0.1, 2)                   ��\n",
      "��──���──������───��─��─��─��──┼───��──�����──�����──�����─���─�����──���──�����┤\n",
      "│ enable_mixup      �� True                       │\n",
      "├─�����──�����──�����──�����──�����┼─�����──�����──���───��─�����──�����────�����─┤\n",
      "│ mixup_scale       �� (0.5, 1.5)                 │\n",
      "├─�����──�����──���───�����──����┼��������──���───��──�����──�����──�����──�����─�����\n",
      "��� shear             ��� 2.0                        │\n",
      "├�����──�����──�����──�����──�����─�����─�����──�����──�����──�����──�����──�����──�����┤\n",
      "│ warmup_epochs     ��� 5                          │\n",
      "├�����──�����──�����──�����──�����─┼���──�����──�����──�����──�����─�����──�����──�����┤\n",
      "│ max_epoch         ��� 300                        ��\n",
      "├─��──�����──�����──�����──�����─┼�����──�����──�����──�����──�����──�����──����─�����\n",
      "�� warmup_lr         │ 0                          │\n",
      "├�����─��──�����──�����──�����──�����──�����──�����──�����──��───����─�����──�����─┤\n",
      "│ min_lr_ratio      �� 0.05                       │\n",
      "├─�����──�����─��──�����──��──���┼──�����──�����──�����─�����──�����──�����──�����─┤\n",
      "│ basic_lr_per_img  ��� 0.00015625                 ��\n",
      "��─�����──�����──��──���─��──��─┼�����──�����──�����──�����──��──�����──���───��┤\n",
      "│ scheduler         ��� 'yoloxwarmcos'             ��\n",
      "��──���──��──������──�����──�����─��──�����─�����──�����─�����──�����──�����──�����──���\n",
      "�� no_aug_epochs     │ 15                         ���\n",
      "����─�����──�����──��──�����──�����┼─���─�����──�����──�����──��──�����──�����──����┤\n",
      "│ ema               │ True                       │\n",
      "�����──��──�����──��──�����──��─┼�����──�����──��─���──�����─�����─�����──�����─������┤\n",
      "�� weight_decay      ��� 0.0005                     │\n",
      "├─�����─�����──�����──�����─������──�����─������──�����──�����──�����─���──�����─������──�����\n",
      "�� momentum          ��� 0.9                        │\n",
      "├─�����─������──�����─�����──�����──���─�����──��──�����──�����──��──�����────�����─┤\n",
      "│ save_history_ckpt ��� True                       ��\n",
      "├──�����──�����──�����─�����──�����┼─�����─������──������──�����──�����──�����──�����─�����\n",
      "│ exp_name          ��� 'yolox_s'                  ��\n",
      "��──�����─�����──�����─�����──���─��┼──────�����─�����──�����──�����─��������─�����──���\n",
      "��� test_size         │ (640, 640)                 │\n",
      "├─���──��──�����──�����──�����──�����──�����──�����──�����──�����──�����──�����──�����\n",
      "�� test_conf         │ 0.01                       ���\n",
      "�����─�����────�����──�����──�����─┼�����──��──�����──�����──�����──�����──�����─�����┤\n",
      "│ nmsthre           ��� 0.65                       ��\n",
      "��══�����══���═�����══����═�����══�����══�����══�����══�����══����══��══�����══�����╛\n",
      "2024-08-27 22:05:05 | INFO     | yolox.core.trainer:145 - Model Summary: Params: 8.97M, Gflops: 26.93\n",
      "2024-08-27 22:05:05 | INFO     | yolox.data.datasets.coco:63 - loading annotations into memory...\n",
      "2024-08-27 22:05:15 | INFO     | yolox.data.datasets.coco:63 - Done (t=10.46s)\n",
      "2024-08-27 22:05:15 | INFO     | pycocotools.coco:86 - creating index...\n",
      "2024-08-27 22:05:16 | INFO     | pycocotools.coco:86 - index created!\n",
      "2024-08-27 22:05:40 | INFO     | yolox.core.trainer:162 - init prefetcher, this might take one minute or less...\n",
      "2024-08-27 22:05:40 | INFO     | yolox.data.datasets.coco:63 - loading annotations into memory...\n",
      "2024-08-27 22:05:40 | INFO     | yolox.data.datasets.coco:63 - Done (t=0.26s)\n",
      "2024-08-27 22:05:40 | INFO     | pycocotools.coco:86 - creating index...\n",
      "2024-08-27 22:05:40 | INFO     | pycocotools.coco:86 - index created!\n",
      "2024-08-27 22:05:41 | INFO     | yolox.core.trainer:199 - Training start...\n",
      "2024-08-27 22:05:41 | INFO     | yolox.core.trainer:200 - \n",
      "YOLOX(\n",
      "  (backbone): YOLOPAFPN(\n",
      "    (backbone): CSPDarknet(\n",
      "      (stem): Focus(\n",
      "        (conv): BaseConv(\n",
      "          (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (dark2): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark3): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (2): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark4): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (2): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark5): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): SPPBottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): ModuleList(\n",
      "            (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "            (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
      "            (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (lateral_conv0): BaseConv(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_p4): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reduce_conv1): BaseConv(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_p3): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bu_conv2): BaseConv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_n3): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bu_conv1): BaseConv(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_n4): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): YOLOXHead(\n",
      "    (cls_convs): ModuleList(\n",
      "      (0-2): 3 x Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reg_convs): ModuleList(\n",
      "      (0-2): 3 x Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls_preds): ModuleList(\n",
      "      (0-2): 3 x Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (reg_preds): ModuleList(\n",
      "      (0-2): 3 x Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (obj_preds): ModuleList(\n",
      "      (0-2): 3 x Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (stems): ModuleList(\n",
      "      (0): BaseConv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): BaseConv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): BaseConv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (l1_loss): L1Loss()\n",
      "    (bcewithlog_loss): BCEWithLogitsLoss()\n",
      "    (iou_loss): IOUloss()\n",
      "  )\n",
      ")\n",
      "2024-08-27 22:05:41 | INFO     | yolox.core.trainer:221 - ---> start train epoch 1\n",
      "TTTTTTTTT STARTING TRAIN_ONE_ITER\n",
      "\n",
      "2024-08-27 22:05:41.000859:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:41.000860:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_728667847965197534+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "TTTTTTTTTTTT inps = tensor([[[[116., 116., 110.,  ..., 138., 137., 135.],\n",
      "          [111., 110., 106.,  ..., 138., 135., 132.],\n",
      "          [108., 114., 115.,  ..., 141., 140., 136.],\n",
      "          ...,\n",
      "          [125., 126., 126.,  ...,  91.,  91.,  91.],\n",
      "          [125., 125., 126.,  ...,  91.,  91.,  91.],\n",
      "          [125., 125., 126.,  ...,  91.,  91.,  91.]],\n",
      "\n",
      "         [[120., 120., 114.,  ..., 132., 132., 130.],\n",
      "          [115., 113., 109.,  ..., 132., 130., 126.],\n",
      "          [111., 117., 118.,  ..., 136., 135., 130.],\n",
      "          ...,\n",
      "          [120., 120., 121.,  ...,  91.,  91.,  91.],\n",
      "          [120., 120., 121.,  ...,  91.,  91.,  91.],\n",
      "          [120., 120., 121.,  ...,  91.,  91.,  91.]],\n",
      "\n",
      "         [[123., 124., 118.,  ..., 133., 134., 131.],\n",
      "          [118., 117., 113.,  ..., 134., 131., 128.],\n",
      "          [115., 121., 122.,  ..., 136., 135., 131.],\n",
      "          ...,\n",
      "          [120., 120., 121.,  ...,  91.,  91.,  91.],\n",
      "          [120., 120., 121.,  ...,  91.,  91.,  91.],\n",
      "          [120., 120., 121.,  ...,  91.,  91.,  91.]]],\n",
      "\n",
      "\n",
      "        [[[176., 176., 176.,  ..., 114.,  57.,  57.],\n",
      "          [177., 177., 177.,  ..., 114.,  57.,  57.],\n",
      "          [178., 177., 178.,  ..., 114.,  57.,  57.],\n",
      "          ...,\n",
      "          [132., 131., 133.,  ..., 114.,  57.,  57.],\n",
      "          [ 57.,  57.,  57.,  ...,  57.,  57.,  57.],\n",
      "          [ 57.,  57.,  57.,  ...,  57.,  57.,  57.]],\n",
      "\n",
      "         [[176., 176., 176.,  ..., 114.,  57.,  57.],\n",
      "          [177., 177., 177.,  ..., 114.,  57.,  57.],\n",
      "          [178., 177., 178.,  ..., 114.,  57.,  57.],\n",
      "          ...,\n",
      "          [132., 131., 133.,  ..., 114.,  57.,  57.],\n",
      "          [ 57.,  57.,  57.,  ...,  57.,  57.,  57.],\n",
      "          [ 57.,  57.,  57.,  ...,  57.,  57.,  57.]],\n",
      "\n",
      "         [[176., 176., 176.,  ..., 114.,  57.,  57.],\n",
      "          [177., 177., 177.,  ..., 114.,  57.,  57.],\n",
      "          [178., 177., 178.,  ..., 114.,  57.,  57.],\n",
      "          ...,\n",
      "          [132., 131., 133.,  ..., 114.,  57.,  57.],\n",
      "          [ 57.,  57.,  57.,  ...,  57.,  57.,  57.],\n",
      "          [ 57.,  57.,  57.,  ...,  57.,  57.,  57.]]]], device='xla:0') , inps.size() = torch.Size([2, 3, 640, 640])\n",
      "TTTTTTTTTTTT targets = tensor([[[  0.0000,  31.8476, 525.3153,  63.6952, 229.3694],\n",
      "         [ 23.0000, 122.7936, 258.2494, 156.8897, 340.6287],\n",
      "         [ 23.0000, 294.3783, 300.9252, 375.7800, 254.7496],\n",
      "         ...,\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[ 46.0000,  74.7724, 146.3085, 149.5448,  68.5317],\n",
      "         [  2.0000, 290.7242,  88.8312,  11.8277,  11.8134],\n",
      "         [  0.0000, 214.6137, 138.7858,  87.1082, 121.6023],\n",
      "         ...,\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='xla:0') , targets.size() = torch.Size([2, 120, 5])\n",
      "\n",
      "XXXXXXXXXXXXXXXXXXXX PRINTING labels = tensor([[[  0.0000,  31.8476, 525.3153,  63.6952, 229.3694],\n",
      "         [ 23.0000, 122.7936, 258.2494, 156.8897, 340.6287],\n",
      "         [ 23.0000, 294.3783, 300.9252, 375.7800, 254.7496],\n",
      "         ...,\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[ 46.0000,  74.7724, 146.3085, 149.5448,  68.5317],\n",
      "         [  2.0000, 290.7242,  88.8312,  11.8277,  11.8134],\n",
      "         [  0.0000, 214.6137, 138.7858,  87.1082, 121.6023],\n",
      "         ...,\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]], device='xla:0')\n",
      "XXXXXXXXXXXXXXXXXXXX PRINTING labels.dtype = torch.float32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "XXXXXXXXXXXXXXXXXXXX PRINTING labels_cpu = tensor([[[  0.0000,  31.8476, 525.3153,  63.6952, 229.3694],\n",
      "         [ 23.0000, 122.7936, 258.2494, 156.8897, 340.6287],\n",
      "         [ 23.0000, 294.3783, 300.9252, 375.7800, 254.7496],\n",
      "         ...,\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[ 46.0000,  74.7724, 146.3085, 149.5448,  68.5317],\n",
      "         [  2.0000, 290.7242,  88.8312,  11.8277,  11.8134],\n",
      "         [  0.0000, 214.6137, 138.7858,  87.1082, 121.6023],\n",
      "         ...,\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "XXXXXXXXXXXXXXXXXXXX PRINTING labels_cpu.dtype = torch.float32\n",
      "2024-08-27 22:05:42.000314:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:42.000314:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_3977455422151084136+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "Step 1 - Sum along dim 2: tensor([[  0.5000, 136.0000, 137.0000, 134.0000, 141.0000, 112.0000, 134.0000,\n",
      "         140.0000, 132.0000, 133.0000, 132.0000, 131.0000, 130.0000, 115.0000,\n",
      "          91.0000,  87.0000,  76.0000,  71.0000,  70.0000,  65.0000,  67.0000,\n",
      "          67.0000,  69.0000,  71.0000,  69.0000,  68.0000,  65.0000,  65.0000,\n",
      "          65.0000,  66.0000,  67.0000,  64.0000,  63.0000,  63.0000,  62.0000,\n",
      "          63.0000,  64.0000,  63.0000,  61.0000,  61.0000,  66.0000,  69.0000,\n",
      "          66.0000,  61.0000,  64.0000,  64.0000,  68.0000,  65.0000,  63.0000,\n",
      "          62.0000,  61.0000,  63.0000,  62.0000,  65.0000,  64.0000,  63.0000,\n",
      "          71.0000,  67.0000,  66.0000,  65.0000,  62.0000,  64.0000,  65.0000,\n",
      "          65.0000,  64.0000,  61.0000,  60.0000,  61.0000,  62.0000,  63.0000,\n",
      "          66.0000,  68.0000,  65.0000,  62.0000,  61.0000,  63.0000,  58.0000,\n",
      "          59.0000,  68.0000,  63.0000,  62.0000,  60.0000,  59.0000,  59.0000,\n",
      "          60.0000,  65.0000,  63.0000,  60.0000,  60.0000,  64.0000,  63.0000,\n",
      "          63.0000,  62.0000,  61.0000,  63.0000,  67.0000,  64.0000,  64.0000,\n",
      "          64.0000,  63.0000,  62.0000,  62.0000,  63.0000,  61.0000,  63.0000,\n",
      "          61.0000,  60.0000,  63.0000,  66.0000,  63.0000,  65.0000,  66.0000,\n",
      "          61.0000,  59.0000,  63.0000,  64.0000,  61.0000,  63.0000,  62.0000,\n",
      "          62.0000],\n",
      "        [ 62.0000,  60.0000,  62.0000,  64.0000,  67.0000,  64.0000,  64.0000,\n",
      "          68.0000,  67.0000,  66.0000,  65.0000,  64.0000,  63.0000,  62.0000,\n",
      "          61.0000,  62.0000,  66.0000,  68.0000,  67.0000,  66.0000,  66.0000,\n",
      "          66.0000,  65.0000,  65.0000,  67.0000,  67.0000,  67.0000,  68.0000,\n",
      "          67.0000,  68.0000,  70.0000,  71.0000,  70.0000,  70.0000,  69.0000,\n",
      "          70.0000,  71.0000,  70.0000,  70.0000,  70.0000,  69.0000,  68.0000,\n",
      "          68.0000,  68.0000,  68.0000,  68.0000,  68.0000,  66.0000,  67.0000,\n",
      "          68.0000,  62.0000,  60.0000,  58.0000,  58.0000,  60.0000,  60.0000,\n",
      "          61.0000,  61.0000,  61.0000,  61.0000,  61.0000,  61.0000,  61.0000,\n",
      "          61.0000,  61.0000,  64.0000,  68.0000,  69.0000,  67.0000,  66.0000,\n",
      "          64.0000,  63.0000,  63.0000,  63.0000,  63.0000,  64.0000,  67.0000,\n",
      "          71.0000,  76.0000,  77.0000,  76.0000,  72.0000,  71.0000,  71.0000,\n",
      "          70.0000,  72.0000,  71.0000,  70.0000,  71.0000,  72.0000,  71.0000,\n",
      "          71.0000,  71.0000,  72.0000,  71.0000,  70.0000,  70.0000,  71.0000,\n",
      "          73.0000,  73.0000,  71.0000,  71.0000,  72.0000,  72.0000,  74.0000,\n",
      "          72.0000,  72.0000,  75.0000,  75.0000,  74.0000,  74.0000,  74.0000,\n",
      "          74.0000,  74.0000,  76.0000,  74.0000,  72.0000,  76.0000,  75.0000,\n",
      "          74.0000]], device='xla:0')\n",
      "2024-08-27 22:05:42.000319:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:42.000319:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_12784406447446082144+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "Step 2 - Boolean mask where sum > 0: tensor([[False, False, False,  True, False, False,  True,  True, False, False,\n",
      "          True,  True, False, False,  True,  True, False, False,  True,  True,\n",
      "         False, False,  True,  True, False, False,  True,  True, False, False,\n",
      "          True,  True, False, False,  True,  True, False, False,  True,  True,\n",
      "         False, False,  True,  True, False, False,  True,  True, False, False,\n",
      "          True,  True, False, False,  True,  True, False, False,  True,  True,\n",
      "         False, False,  True,  True, False, False,  True,  True, False, False,\n",
      "          True,  True, False, False,  True,  True, False, False,  True,  True,\n",
      "         False, False,  True,  True, False, False,  True,  True, False, False,\n",
      "          True,  True, False, False,  True,  True, False, False,  True,  True,\n",
      "         False, False,  True,  True, False, False,  True,  True, False, False,\n",
      "          True,  True, False, False,  True,  True, False, False,  True,  True],\n",
      "        [False, False,  True,  True, False, False,  True,  True, False, False,\n",
      "          True,  True, False, False,  True,  True, False, False,  True,  True,\n",
      "         False, False,  True,  True, False, False,  True,  True, False, False,\n",
      "          True,  True, False, False,  True,  True, False, False,  True,  True,\n",
      "         False, False,  True,  True, False, False,  True,  True, False, False,\n",
      "          True,  True, False, False,  True,  True, False, False,  True,  True,\n",
      "         False, False,  True,  True, False, False,  True,  True, False, False,\n",
      "          True,  True, False, False,  True,  True, False, False,  True,  True,\n",
      "         False, False,  True,  True, False, False,  True,  True, False, False,\n",
      "          True,  True, False, False,  True,  True, False, False,  True,  True,\n",
      "         False, False,  True,  True, False, False,  True,  True, False, False,\n",
      "          True,  True, False, False,  True,  True, False, False,  True,  True]],\n",
      "       device='xla:0')\n",
      "2024-08-27 22:05:42.000323:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:42.000323:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_10437825443067299145+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "Step 3 - Final nlabel: tensor([841731191,         0], device='xla:0')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2024-08-27 22:05:42.000325:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:42.000326:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_11250971159319000456+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "XXXXXXXXXXXXXXXXXXXX PRINTING nlabel = tensor([841731191,         0], device='xla:0')\n",
      "\n",
      "\n",
      "\n",
      "XXXXXXXXXXXXXXXXXXXX PRINTING nlabel_cpu = tensor([ 3, 11])\n",
      "XXXXXXXXXXXXXXXXXXXX PRINTING NEW nlabel = tensor([ 3, 11])\n",
      "XXXXXXXXXXXXXXXXXXXX PRINTING nlabel[0] = 3\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX gt_classes = labels[batch_idx: num_gt, 0] = (0, 3, tensor([ 0., 23., 23.]))\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX MODE: gpu\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX gt_classes device: xla:0\n",
      "2024-08-27 22:05:42.000333:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:42.000334:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_5859145738237207923+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-27 22:05:42.000340:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:42.000340:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_4249173920803439261+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "XXXXXXXXXXXXXXXXXXXXXX Shape of fg_mask: torch.Size([8400]), sum: 0\n",
      "XXXXXXXXXXXXXXXXXXXX Shape of bboxes_preds_per_image before masking: torch.Size([8400, 4])\n",
      "\n",
      "Shape of cls_preds before masking : torch.Size([2, 8400, 80])\n",
      "Shape of obj_preds before masking : torch.Size([2, 8400, 1])\n",
      "\n",
      "AAAAAAAAAAAA LINE 462\n",
      "AAAAAAAAAAAA LINE 464\n",
      "AAAAAAAAAAAA LINE 466\n",
      "AAAAAAAAAAAA LINE 468\n",
      "\n",
      "Shape of cls_preds after masking : torch.Size([2083, 80])\n",
      "Shape of obj_preds after masking : torch.Size([2083, 1])\n",
      "\n",
      "XXXXXXXXXXXXXX gt_bboxes_per_image device: xla:0\n",
      "XXXXXXXXXXXXXX bboxes_preds_per_image device: xla:0\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX TL Type = torch.xla.FloatTensor\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX BR Type = torch.xla.FloatTensor\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX output_size = torch.xla.BoolTensor\n",
      "AAAAAAAAAAAA LINE 476\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX DTYPE = torch.float32\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX GT_CLASSES = tensor([ 0., 23., 23.])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX GT_CLASSES.norm() = 32.526912689208984\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX Class values norm: 32.526912689208984, max: 23.0\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX GT_CLASSES.max() = 23.0\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX GT_CLASSES_SHAPE = torch.Size([3])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX NUM_CLASSES = 80\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXX DTYPE = torch.float32\n",
      "XXXXXXXXXXXXXXXXX gt_cls_per_image = tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]]) , SIZE = torch.Size([3, 80])\n",
      "AAAAAAAAAAAA LINE 506\n",
      "Shape of cls_preds_ before multiplication: torch.Size([2083, 80])\n",
      "2024-08-27 22:05:42.000417:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:42.000417:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_1055972773932305163+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "Sample content of cls_preds_ (first element): tensor([ 14.,   7.,   9.,  10.,  10.,  10.,   6.,   6.,   9.,  13.,  12.,  12.,\n",
      "         13.,   8.,  22.,  59.,  59.,  60.,  59.,  59.,  79.,  96.,  90.,  92.,\n",
      "         94.,  99., 106., 104., 106., 110., 111.,  96.,  96.,  87., 119.,  78.,\n",
      "         96., 101., 106., 108., 139., 154., 118., 135., 143., 111.,  72.,  72.,\n",
      "         73.,  71.,  74., 131., 118., 134., 139., 112.,  88.,  91., 116.,  86.,\n",
      "         83.,  79., 114., 114., 114., 114., 114., 114., 114., 114., 114., 114.,\n",
      "        114., 114., 114., 114., 114., 114., 114., 114.], device='xla:0')\n",
      "\n",
      "Shape of obj_preds_ before multiplication: torch.Size([2083, 1])\n",
      "2024-08-27 22:05:42.000493:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:42.000493:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_16608641992978794954+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "Sample content of obj_preds_ (first element): tensor([14.], device='xla:0')\n",
      "\n",
      "Shape of cls_preds_ after multiplication and before unsqueeze and repeat: torch.Size([2083, 80])\n",
      "2024-08-27 22:05:42.000575:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:42.000575:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_8883587954543238859+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "Sample content of cls_preds_ (first element): tensor([ 14.,   7.,   9.,  10.,  10.,  10.,   6.,   6.,   9.,  13.,  12.,  12.,\n",
      "         13.,   8.,  22.,  59.,  59.,  60.,  59.,  59.,  79.,  96.,  90.,  92.,\n",
      "         94.,  99., 106., 104., 106., 110., 111.,  96.,  96.,  87., 119.,  78.,\n",
      "         96., 101., 106., 108., 139., 154., 118., 135., 143., 111.,  72.,  72.,\n",
      "         73.,  71.,  74., 131., 118., 134., 139., 112.,  88.,  91., 116.,  86.,\n",
      "         83.,  79., 114., 114., 114., 114., 114., 114., 114., 114., 114., 114.,\n",
      "        114., 114., 114., 114., 114., 114., 114., 114.], device='xla:0')\n",
      "\n",
      "Shape of gt_cls_per_image after multiplication and beforebefore unsqueeze and repeat: torch.Size([3, 80])\n",
      "Sample content of gt_cls_per_image (first element): tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "2024-08-27 22:05:42 | ERROR    | yolox.core.trainer:80 - Exception in training: Using a target size (torch.Size([3, 2049, 80])) that is different to the input size (torch.Size([3, 2083, 80])) is deprecated. Please ensure they have the same size.\n",
      "2024-08-27 22:05:42 | INFO     | yolox.core.trainer:203 - Training of experiment is done and the best AP is 0.00\n",
      "2024-08-27 22:05:42.000745:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:42.000745:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_3941120121036684346+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-27 22:05:42.000814:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:42.000814:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_15457411607563270555+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-27 22:05:42.000878:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:42.000879:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_18058599337860878096+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-27 22:05:43.000019:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:43.000019:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_2775507971738493895+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-27 22:05:43.000048:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:43.000049:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_3288600609627781372+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-27 22:05:43.000051:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:43.000052:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_8900510789712594047+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-27 22:05:43.000054:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:43.000054:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_5403215385800979758+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-27 22:05:43.000119:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:43.000119:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_10737903924855665161+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-27 22:05:43.000202:  140139  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:43.000203:  140139  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_482252779879477993+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-27 22:05:42 | ERROR    | yolox.core.launch:98 - An error has been caught in function 'launch', process 'MainProcess' (140139), thread 'MainThread' (140374799495808):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'yolox.tools', '__loader__': <_frozen_importlib_external.SourceFileL...\n",
      "           │         └ <code object <module> at 0x7fab8da50c90, file \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/tools/t...\n",
      "           └ <function _run_code at 0x7fab8dbde050>\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "         ��     └ {'__name__': '__main__', '__doc__': None, '__package__': 'yolox.tools', '__loader__': <_frozen_importlib_external.SourceFileL...\n",
      "         └ <code object <module> at 0x7fab8da50c90, file \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/tools/t...\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/tools/train.py\", line 138, in <module>\n",
      "    launch(\n",
      "    └ <function launch at 0x7faacd4b9240>\n",
      "\n",
      "> File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/core/launch.py\", line 98, in launch\n",
      "    main_func(*args)\n",
      "    │          └ (��══����═�����═�����══�����═�����══�����══���══�����═�����══���══�����═�����══�����═�����══�����══���══�����══���══�����══�����══���══�����══�����═�����══�����═������═══��══�����══�����══�����══�����══�����══�����═�����═...\n",
      "    └ <function main at 0x7faacd4b8e50>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/tools/train.py\", line 118, in main\n",
      "    trainer.train()\n",
      "    ��       ��� <function Trainer.train at 0x7faa89c80dc0>\n",
      "    ��� <yolox.core.trainer.Trainer object at 0x7faa89cb2320>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/core/trainer.py\", line 78, in train\n",
      "    self.train_in_epoch()\n",
      "    ��    └ <function Trainer.train_in_epoch at 0x7faa89ac64d0>\n",
      "    └ <yolox.core.trainer.Trainer object at 0x7faa89cb2320>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/core/trainer.py\", line 88, in train_in_epoch\n",
      "    self.train_in_iter()\n",
      "    │    ��� <function Trainer.train_in_iter at 0x7faa89ac6e60>\n",
      "    └ <yolox.core.trainer.Trainer object at 0x7faa89cb2320>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/core/trainer.py\", line 95, in train_in_iter\n",
      "    self.train_one_iter()\n",
      "    │    └ <function Trainer.train_one_iter at 0x7faa89ac6ef0>\n",
      "    └ <yolox.core.trainer.Trainer object at 0x7faa89cb2320>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/core/trainer.py\", line 115, in train_one_iter\n",
      "    outputs = self.model(inps, targets)\n",
      "              │    ���     │     └ tensor([[[  0.0000,  31.8476, 525.3153,  63.6952, 229.3694],\n",
      "              │    │     │                [ 23.0000, 122.7936, 258.2494, 156.8897, 340.6287],\n",
      "              ��    │     │          ...\n",
      "              │    │     └ tensor([[[[116., 116., 110.,  ..., 138., 137., 135.],\n",
      "              │    │                 [111., 110., 106.,  ..., 138., 135., 132.],\n",
      "              ���    │                 [108., ...\n",
      "              │    └ YOLOX(\n",
      "              │        (backbone): YOLOPAFPN(\n",
      "              │          (backbone): CSPDarknet(\n",
      "              │            (stem): Focus(\n",
      "              │              (conv): BaseConv(\n",
      "              │                (conv): ...\n",
      "              └ <yolox.core.trainer.Trainer object at 0x7faa89cb2320>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           │    │           │       └ {}\n",
      "           │    │           └ (tensor([[[[116., 116., 110.,  ..., 138., 137., 135.],\n",
      "           │    │                       [111., 110., 106.,  ..., 138., 135., 132.],\n",
      "           │    │                       [108.,...\n",
      "           │    ��� <function Module._call_impl at 0x7faae17e5b40>\n",
      "           └ YOLOX(\n",
      "               (backbone): YOLOPAFPN(\n",
      "                 (backbone): CSPDarknet(\n",
      "                   (stem): Focus(\n",
      "                     (conv): BaseConv(\n",
      "                       (conv): ...\n",
      "  File \"/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ���             │       └ {}\n",
      "           │             └ (tensor([[[[116., 116., 110.,  ..., 138., 137., 135.],\n",
      "           │                         [111., 110., 106.,  ..., 138., 135., 132.],\n",
      "           │                         [108.,...\n",
      "           ��� <bound method YOLOX.forward of YOLOX(\n",
      "               (backbone): YOLOPAFPN(\n",
      "                 (backbone): CSPDarknet(\n",
      "                   (stem): Focus(\n",
      "                     (conv...\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/models/yolox.py\", line 34, in forward\n",
      "    loss, iou_loss, conf_loss, cls_loss, l1_loss, num_fg = self.head(\n",
      "                                                           └ YOLOX(\n",
      "                                                               (backbone): YOLOPAFPN(\n",
      "                                                                 (backbone): CSPDarknet(\n",
      "                                                                   (stem): Focus(\n",
      "                                                                     (conv): BaseConv(\n",
      "                                                                       (conv): ...\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           │    │           │       └ {}\n",
      "           │    │           └ ((tensor([[[[ 14.,   7.,   9.,  ..., 114., 114., 114.],\n",
      "           │    │                       [114., 114., 114.,  ...,  79.,  79.,  78.],\n",
      "           │    │                       [ 77....\n",
      "           │    └ <function Module._call_impl at 0x7faae17e5b40>\n",
      "           └ YOLOXHead(\n",
      "               (cls_convs): ModuleList(\n",
      "                 (0-2): 3 x Sequential(\n",
      "                   (0): BaseConv(\n",
      "                     (conv): Conv2d(128, 128, kernel...\n",
      "  File \"/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           │             │       �� {}\n",
      "           │             └ ((tensor([[[[ 14.,   7.,   9.,  ..., 114., 114., 114.],\n",
      "           ��                         [114., 114., 114.,  ...,  79.,  79.,  78.],\n",
      "           │                         [ 77....\n",
      "           └ <bound method YOLOXHead.forward of YOLOXHead(\n",
      "               (cls_convs): ModuleList(\n",
      "                 (0-2): 3 x Sequential(\n",
      "                   (0): BaseConv(\n",
      "                 ...\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/models/yolo_head.py\", line 192, in forward\n",
      "    return self.get_losses(\n",
      "           │    └ <function YOLOXHead.get_losses at 0x7faa89b11cf0>\n",
      "           └ YOLOXHead(\n",
      "               (cls_convs): ModuleList(\n",
      "                 (0-2): 3 x Sequential(\n",
      "                   (0): BaseConv(\n",
      "                     (conv): Conv2d(128, 128, kernel...\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/models/yolo_head.py\", line 335, in get_losses\n",
      "    ) = self.get_assignments(\n",
      "        │    └ <function YOLOXHead.get_assignments at 0x7faa89b11ea0>\n",
      "        └ YOLOXHead(\n",
      "            (cls_convs): ModuleList(\n",
      "              (0-2): 3 x Sequential(\n",
      "                (0): BaseConv(\n",
      "                  (conv): Conv2d(128, 128, kernel...\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           │     │       └ {}\n",
      "           ���     └ (YOLOXHead(\n",
      "           │         (cls_convs): ModuleList(\n",
      "           │           (0-2): 3 x Sequential(\n",
      "           │             (0): BaseConv(\n",
      "           │               (conv): Conv2d(128, 128, kerne...\n",
      "           └ <function YOLOXHead.get_assignments at 0x7faa89b11e10>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/models/yolo_head.py\", line 536, in get_assignments\n",
      "    pair_wise_cls_loss = F.binary_cross_entropy(\n",
      "                         ��� └ <function binary_cross_entropy at 0x7faacf781a20>\n",
      "                         └ <module 'torch.nn.functional' from '/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torc...\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch/nn/functional.py\", line 3113, in binary_cross_entropy\n",
      "    raise ValueError(\n",
      "\n",
      "ValueError: Using a target size (torch.Size([3, 2049, 80])) that is different to the input size (torch.Size([3, 2083, 80])) is deprecated. Please ensure they have the same size.\n",
      "2024-08-27 22:05:49.000216:  140122  INFO ||NEURON_PARALLEL_COMPILE||: New graph list from script 19: /home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_728667847965197534+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_3977455422151084136+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_12784406447446082144+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_10437825443067299145+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_11250971159319000456+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_5859145738237207923+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_4249173920803439261+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_1055972773932305163+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_16608641992978794954+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_8883587954543238859+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_3941120121036684346+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_15457411607563270555+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_18058599337860878096+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_2775507971738493895+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_3288600609627781372+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_8900510789712594047+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_5403215385800979758+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_10737903924855665161+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_482252779879477993+ade7b014/model.hlo_module.pb\n",
      "2024-08-27 22:05:49.000216:  140122  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-27 22:05:49.000248:  140325  INFO ||NEURON_PARALLEL_COMPILE||: worker 0 starts dynamic scheduleing on 19....\n",
      "2024-08-27 22:05:49.000249:  140326  INFO ||NEURON_PARALLEL_COMPILE||: worker 1 starts dynamic scheduleing on 19....\n",
      "2024-08-27 22:05:49.000249:  140327  INFO ||NEURON_PARALLEL_COMPILE||: worker 2 starts dynamic scheduleing on 19....\n",
      "2024-08-27 22:05:49.000249:  140328  INFO ||NEURON_PARALLEL_COMPILE||: worker 3 starts dynamic scheduleing on 19....\n",
      "2024-08-27 22:05:49.000249:  140329  INFO ||NEURON_PARALLEL_COMPILE||: worker 4 starts dynamic scheduleing on 19....\n",
      "2024-08-27 22:05:49.000249:  140330  INFO ||NEURON_PARALLEL_COMPILE||: worker 5 starts dynamic scheduleing on 19....\n",
      "2024-08-27 22:05:49.000249:  140331  INFO ||NEURON_PARALLEL_COMPILE||: worker 6 starts dynamic scheduleing on 19....\n",
      "2024-08-27 22:05:49.000249:  140332  INFO ||NEURON_PARALLEL_COMPILE||: worker 7 starts dynamic scheduleing on 19....\n",
      "2024-08-27 22:05:49.000250:  140327  INFO ||NEURON_PARALLEL_COMPILE||: worker 2 finished with num of tasks 0....\n",
      "2024-08-27 22:05:49.000250:  140330  INFO ||NEURON_PARALLEL_COMPILE||: worker 5 finished with num of tasks 0....\n",
      "2024-08-27 22:05:49.000250:  140332  INFO ||NEURON_PARALLEL_COMPILE||: worker 7 finished with num of tasks 0....\n",
      "2024-08-27 22:05:49.000251:  140331  INFO ||NEURON_PARALLEL_COMPILE||: worker 6 finished with num of tasks 0....\n",
      "2024-08-27 22:05:49.000251:  140325  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/0567073c-4da7-40a3-a546-b3aea9d7c017/model.MODULE_1055972773932305163+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/0567073c-4da7-40a3-a546-b3aea9d7c017/model.MODULE_1055972773932305163+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "2024-08-27 22:05:49.000252:  140326  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/a85ab865-0b8a-4fe8-bd8a-b7653b27615d/model.MODULE_16608641992978794954+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/a85ab865-0b8a-4fe8-bd8a-b7653b27615d/model.MODULE_16608641992978794954+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "2024-08-27 22:05:49.000252:  140329  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/e5bef35c-1b87-4a9a-bff5-21a7c6387852/model.MODULE_4249173920803439261+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/e5bef35c-1b87-4a9a-bff5-21a7c6387852/model.MODULE_4249173920803439261+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "2024-08-27 22:05:49.000252:  140327  INFO ||NEURON_CACHE||: Current remaining items are 2, locked are 4, failed are 0, done are 94, total is 100\n",
      "2024-08-27 22:05:49.000253:  140328  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/538b170d-9b2b-4421-9c15-7c665b054d8f/model.MODULE_8883587954543238859+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/538b170d-9b2b-4421-9c15-7c665b054d8f/model.MODULE_8883587954543238859+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "2024-08-27 22:05:49.000253:  140332  INFO ||NEURON_CACHE||: Current remaining items are 2, locked are 4, failed are 0, done are 94, total is 100\n",
      "2024-08-27 22:05:49.000253:  140330  INFO ||NEURON_CACHE||: Current remaining items are 2, locked are 4, failed are 0, done are 94, total is 100\n",
      "2024-08-27 22:05:49.000254:  140331  INFO ||NEURON_CACHE||: Current remaining items are 2, locked are 4, failed are 0, done are 94, total is 100\n",
      "....\n",
      "Compiler status PASS\n",
      "2024-08-27 22:05:54.000728:  140329  INFO ||NEURON_PARALLEL_COMPILE||: worker 4 finished with num of tasks 1....\n",
      "2024-08-27 22:05:54.000730:  140329  INFO ||NEURON_CACHE||: Current remaining items are 2, locked are 3, failed are 0, done are 95, total is 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:11\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:364\u001b[0m, in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_call\u001b[39m(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run command with arguments.  Wait for command to complete.  If\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m    the exit code was zero then return, otherwise raise\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03m    CalledProcessError.  The CalledProcessError object will have the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    check_call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retcode:\n\u001b[1;32m    366\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:347\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m# Including KeyboardInterrupt, wait handled that.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m         p\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1959\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1917\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......\n",
      "Compiler status PASS\n",
      "2024-08-27 22:06:45.000352:  140326  INFO ||NEURON_PARALLEL_COMPILE||: worker 1 finished with num of tasks 1....\n",
      "2024-08-27 22:06:45.000354:  140326  INFO ||NEURON_CACHE||: Current remaining items are 2, locked are 2, failed are 0, done are 96, total is 100\n",
      "............\n",
      "Compiler status PASS\n",
      "2024-08-27 22:08:33.000001:  140328  INFO ||NEURON_PARALLEL_COMPILE||: worker 3 finished with num of tasks 1....\n",
      "2024-08-27 22:08:33.000003:  140328  INFO ||NEURON_CACHE||: Current remaining items are 2, locked are 1, failed are 0, done are 97, total is 100\n",
      "\n",
      "Compiler status PASS\n",
      "2024-08-27 22:08:41.000771:  140325  INFO ||NEURON_PARALLEL_COMPILE||: worker 0 finished with num of tasks 1....\n",
      "2024-08-27 22:08:41.000773:  140325  INFO ||NEURON_CACHE||: Current remaining items are 2, locked are 0, failed are 0, done are 98, total is 100\n",
      "2024-08-27 22:08:41.000786:  140122  INFO ||NEURON_PARALLEL_COMPILE||: {\n",
      "    \"compilation_summary\": {\n",
      "        \"true\": 4\n",
      "    },\n",
      "    \"compilation_report\": {\n",
      "        \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_1055972773932305163+ade7b014/model.hlo_module.pb\": {\n",
      "            \"status\": true,\n",
      "            \"retry\": 0,\n",
      "            \"compile_time\": 172.52165293693542\n",
      "        },\n",
      "        \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_16608641992978794954+ade7b014/model.hlo_module.pb\": {\n",
      "            \"status\": true,\n",
      "            \"retry\": 0,\n",
      "            \"compile_time\": 56.10198354721069\n",
      "        },\n",
      "        \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_8883587954543238859+ade7b014/model.hlo_module.pb\": {\n",
      "            \"status\": true,\n",
      "            \"retry\": 0,\n",
      "            \"compile_time\": 163.75112318992615\n",
      "        },\n",
      "        \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_4249173920803439261+ade7b014/model.hlo_module.pb\": {\n",
      "            \"status\": true,\n",
      "            \"retry\": 0,\n",
      "            \"compile_time\": 5.478170156478882\n",
      "        }\n",
      "    },\n",
      "    \"start_time\": 1724796349.2166984,\n",
      "    \"compilation_time\": 172.56974935531616\n",
      "}\n",
      "2024-08-27 22:08:41.000786:  140122  INFO ||NEURON_PARALLEL_COMPILE||: Total graphs: 4\n",
      "2024-08-27 22:08:41.000786:  140122  INFO ||NEURON_PARALLEL_COMPILE||: Total successful compilations: 4\n",
      "2024-08-27 22:08:41.000786:  140122  INFO ||NEURON_PARALLEL_COMPILE||: Total failed compilations: 0\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import subprocess\n",
    "print(\"Compile model\")\n",
    "COMPILE_CMD = f\"\"\"{env_var_options} neuron_parallel_compile python -m \\\n",
    "   yolox.tools.train \\\n",
    "    -n {model} \\\n",
    "    -d {num_accelerators} \\\n",
    "    -b {total_batch_size} \\\n",
    "    \"\"\"\n",
    "\n",
    "print(f'Running command: \\n{COMPILE_CMD}')\n",
    "if subprocess.check_call(COMPILE_CMD,shell=True):\n",
    "   print(\"There was an error with the compilation command\")\n",
    "else:\n",
    "   print(\"Compilation Success!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "Running command: \n",
      "\n",
      "   NEURON_RT_ASYNC_EXEC_MAX_INFLIGHT_REQUESTS=3  NEURON_CC_FLAGS='--cache_dir=./compiler_cache --model-type=cnn-training' python -m    yolox.tools.train     -n yolox-s     -d 1     -b 2     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: nvidia-smi: not found\n",
      "2024-08-26 18:12:24 | INFO     | yolox.core.trainer:142 - args: Namespace(experiment_name='yolox_s', name='yolox-s', dist_backend='nccl', dist_url=None, batch_size=2, devices=1, exp_file=None, resume=False, ckpt=None, start_epoch=None, num_machines=1, machine_rank=0, fp16=False, cache=None, occupy=False, logger='tensorboard', opts=[])\n",
      "2024-08-26 18:12:24 | INFO     | yolox.core.trainer:143 - exp value:\n",
      "╒═══════════════════╤════════════════════════════╕\n",
      "│ keys              │ values                     │\n",
      "╞═══════════════════╪════════════════════════════╡\n",
      "│ seed              │ None                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ output_dir        │ './YOLOX_outputs'          │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ print_interval    │ 10                         │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ eval_interval     │ 10                         │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ dataset           │ None                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ num_classes       │ 80                         │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ depth             │ 0.33                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ width             │ 0.5                        │\n",
      "├──────────────────��┼────────────────────────────┤\n",
      "│ act               │ 'silu'                     │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ data_num_workers  │ 4                          │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ input_size        │ (640, 640)                 │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ multiscale_range  │ 5                          │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ data_dir          │ None                       │\n",
      "├─────���─────────────┼────────────────────────────┤\n",
      "│ train_ann         │ 'instances_train2017.json' │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ val_ann           │ 'instances_val2017.json'   │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ test_ann          │ 'instances_test2017.json'  │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ mosaic_prob       │ 1.0                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ mixup_prob        │ 1.0                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ hsv_prob          │ 1.0                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ flip_prob         │ 0.5                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ degrees           │ 10.0                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ translate         │ 0.1                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ mosaic_scale      │ (0.1, 2)                   │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ enable_mixup      │ True                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ mixup_scale       │ (0.5, 1.5)                 │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ shear             │ 2.0                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ warmup_epochs     │ 5                          │\n",
      "├───────────────────┼──────────────��─────────────┤\n",
      "│ max_epoch         │ 300                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ warmup_lr         │ 0                          │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ min_lr_ratio      │ 0.05                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ basic_lr_per_img  │ 0.00015625                 │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ scheduler         │ 'yoloxwarmcos'             │\n",
      "├───────────────────┼─���──────────────────────────┤\n",
      "│ no_aug_epochs     │ 15                         │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ ema               │ True                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ weight_decay      │ 0.0005                     │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ momentum          │ 0.9                        │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ save_history_ckpt │ True                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ exp_name          │ 'yolox_s'                  │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ test_size         │ (640, 640)                 │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ test_conf         │ 0.01                       │\n",
      "├───────────────────┼────────────────────────────┤\n",
      "│ nmsthre           │ 0.65                       │\n",
      "╘═══════════════════╧════════════════════════════╛\n",
      "2024-08-26 18:12:24 | INFO     | yolox.core.trainer:149 - Model Summary: Params: 8.97M, Gflops: 26.93\n",
      "2024-08-26 18:12:24 | INFO     | yolox.data.datasets.coco:63 - loading annotations into memory...\n",
      "2024-08-26 18:12:34 | INFO     | yolox.data.datasets.coco:63 - Done (t=10.64s)\n",
      "2024-08-26 18:12:34 | INFO     | pycocotools.coco:86 - creating index...\n",
      "2024-08-26 18:12:35 | INFO     | pycocotools.coco:86 - index created!\n",
      "2024-08-26 18:12:59 | INFO     | yolox.core.trainer:168 - init prefetcher, this might take one minute or less...\n",
      "2024-08-26 18:12:59 | ERROR    | yolox.core.launch:98 - An error has been caught in function 'launch', process 'MainProcess' (18347), thread 'MainThread' (139812079170176):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'yolox.tools', '__loader__': <_frozen_importlib_external.SourceFileL...\n",
      "           │         └ <code object <module> at 0x7f2888e64c90, file \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/tools/t...\n",
      "           └ <function _run_code at 0x7f2888ff2050>\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'yolox.tools', '__loader__': <_frozen_importlib_external.SourceFileL...\n",
      "         └ <code object <module> at 0x7f2888e64c90, file \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/tools/t...\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/tools/train.py\", line 138, in <module>\n",
      "    launch(\n",
      "    └ <function launch at 0x7f27c88b9240>\n",
      "\n",
      "> File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/core/launch.py\", line 98, in launch\n",
      "    main_func(*args)\n",
      "    │          └ (╒═══════════════════╤═══════════════════════════════════════════════════════════════════════════════════════════════════════...\n",
      "    └ <function main at 0x7f27c88b8e50>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/tools/train.py\", line 118, in main\n",
      "    trainer.train()\n",
      "    │       └ <function Trainer.train at 0x7f278dda2a70>\n",
      "    └ <yolox.core.trainer.Trainer object at 0x7f278cabd630>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/core/trainer.py\", line 85, in train\n",
      "    self.before_train()\n",
      "    │    └ <function Trainer.before_train at 0x7f278cab6ef0>\n",
      "    └ <yolox.core.trainer.Trainer object at 0x7f278cabd630>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/core/trainer.py\", line 169, in before_train\n",
      "    self.prefetcher = DataPrefetcher(self.train_loader)\n",
      "    │                 │              │    └ <yolox.data.dataloading.DataLoader object at 0x7f27aaad44c0>\n",
      "    │                 │              └ <yolox.core.trainer.Trainer object at 0x7f278cabd630>\n",
      "    │                 └ <class 'yolox.data.data_prefetcher.DataPrefetcher'>\n",
      "    └ <yolox.core.trainer.Trainer object at 0x7f278cabd630>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/torch-neuronx/training/neuron-adoption/yolox/data/data_prefetcher.py\", line 18, in __init__\n",
      "    self.stream = torch.cuda.Stream()\n",
      "    │             │     │    └ <class 'torch.cuda.streams.Stream'>\n",
      "    │             │     └ <module 'torch.cuda' from '/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch/cuda/__...\n",
      "    │             └ <module 'torch' from '/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch/__init__.py'>\n",
      "    └ <yolox.data.data_prefetcher.DataPrefetcher object at 0x7f278cabe980>\n",
      "\n",
      "  File \"/home/ubuntu/aws-neuron-samples/aws_neuron_venv_pytorch/lib/python3.10/site-packages/torch/cuda/streams.py\", line 34, in __new__\n",
      "    return super().__new__(cls, priority=priority, **kwargs)\n",
      "                           │             │           └ {}\n",
      "                           │             └ 0\n",
      "                           └ <class 'torch.cuda.streams.Stream'>\n",
      "\n",
      "RuntimeError: CUDA error: CUDA driver version is insufficient for CUDA runtime version\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Device-side assertions were explicitly omitted for this error check; the error probably arose while initializing the DSA handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Successful!!!\n",
      "CPU times: user 8.42 ms, sys: 0 ns, total: 8.42 ms\n",
      "Wall time: 51.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Train model\")\n",
    "RUN_CMD = f\"\"\"\n",
    "   {env_var_options} python -m \\\n",
    "   yolox.tools.train \\\n",
    "    -n {model} \\\n",
    "    -d {num_accelerators} \\\n",
    "    -b {total_batch_size} \\\n",
    "    \"\"\"\n",
    "\n",
    "print(f'Running command: \\n{RUN_CMD}')\n",
    "if subprocess.check_call(RUN_CMD,shell=True):\n",
    "   print(\"There was an error with the fine-tune command\")\n",
    "else:\n",
    "   print(\"Fine-tune Successful!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_xla.distributed.xla_backend\n",
    "import torch_xla\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([41., 50.], device='xla:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_classes = torch.tensor([41., 50.], device='xla:0')\n",
    "gt_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-27 19:52:35.000128:  117179  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-08-27 19:52:35.000131:  117179  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/276695cf-a353-49a6-8285-b48a69839d84/model.MODULE_5829231090852593460+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/276695cf-a353-49a6-8285-b48a69839d84/model.MODULE_5829231090852593460+d41d8cd9.neff --verbose=35\n",
      ".\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(64.6607, device='xla:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_classes.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50., device='xla:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_classes.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "gt_classes = torch.tensor([ 0.,  0., 14., 56., 60.])\n",
    "num_classes = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_cls_per_image = (\n",
    "    F.one_hot((gt_classes).to(torch.int64), num_classes)\n",
    "    .float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (582223232.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[28], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    cls_preds_ = [1:1:2050, 1:1:80]\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_venv_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
