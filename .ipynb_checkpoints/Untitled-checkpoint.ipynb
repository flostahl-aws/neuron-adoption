{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355abaae-dcce-4b51-9744-5a41ff9d2d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"yolox-s\"\n",
    "num_accelerators = 1\n",
    "total_batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb363a9f-fbd6-48ae-8c8a-23bed718ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_var_options = \"NEURON_RT_ASYNC_EXEC_MAX_INFLIGHT_REQUESTS=3  \" + \\\n",
    "    \"NEURON_CC_FLAGS=\\'--cache_dir=./compiler_cache --model-type=cnn-training\\'\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c029114-86ef-4354-85ad-cc9beee29c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /opt/aws_neuronx_venv_pytorch_2_1/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32761f7-6075-413c-8b5b-9e9388e92eb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compile model\n",
      "Running command: \n",
      "NEURON_RT_ASYNC_EXEC_MAX_INFLIGHT_REQUESTS=3  NEURON_CC_FLAGS='--cache_dir=./compiler_cache --model-type=cnn-training' neuron_parallel_compile python -m    yolox.tools.train     -n yolox-s     -d 1     -b 2     \n",
      "2024-08-26 16:48:28.000822:  20405  INFO ||NEURON_PARALLEL_COMPILE||: Removing existing workdir /tmp/ubuntu/parallel_compile_workdir\n",
      "2024-08-26 16:48:28.000822:  20405  INFO ||NEURON_PARALLEL_COMPILE||: Running trial run (add option to terminate trial run early; also ignore trial run's generated outputs, i.e. loss, checkpoints)\n",
      "2024-08-26 16:48:28.000822:  20405  INFO ||NEURON_PARALLEL_COMPILE||: Running cmd: ['python', '-m', 'yolox.tools.train', '-n', 'yolox-s', '-d', '1', '-b', '2']\n",
      "/bin/sh: 1: nvidia-smi: not found\n",
      "2024-08-26 16:48:39 | INFO     | yolox.core.trainer:148 - args: Namespace(experiment_name='yolox_s', name='yolox-s', dist_backend='nccl', dist_url=None, batch_size=2, devices=1, exp_file=None, resume=False, ckpt=None, start_epoch=None, num_machines=1, machine_rank=0, fp16=False, cache=None, occupy=False, logger='tensorboard', opts=[])\n",
      "2024-08-26 16:48:39 | INFO     | yolox.core.trainer:149 - exp value:\n",
      "╒═��═�����═══�����═����═��══���═���═�����═��═════���═════��══��═��══════╕\n",
      "│ keys              │ values                     ��\n",
      "╞══════���═��══���════���═��╪═════════��══���═��══��══���═��═════╡\n",
      "│ seed              │ None                       │\n",
      "├���─��──��──���────���──���──��──��──���─��────────���─────��────���┤\n",
      "│ output_dir        �� './YOLOX_outputs'          ��\n",
      "├─���─────���─��──��──────┼────��────���──���────���──���──���──���─��\n",
      "│ print_interval    │ 10                         │\n",
      "��──���─��─────���─��──���─��─┼───��──���─────���─────���─────���─��─┤\n",
      "�� eval_interval     │ 10                         │\n",
      "��───���──���────���──���────���─��───────��──���─��─────���──���────┤\n",
      "│ dataset           │ None                       │\n",
      "���──���──��──��──���─��─────┼─��────��───────��──��──���──���─��──┤\n",
      "│ num_classes       │ 80                         │\n",
      "├───���────���─��─────��──���─���──��──���────���──���──���─��───────��\n",
      "│ depth             │ 0.33                       │\n",
      "├─���────��──��──��──���───┼─��──��──���──���───���──────���───���──┤\n",
      "│ width             │ 0.5                        │\n",
      "├���──────���─────���──���──���──���─────���─��──��──��──���────────��\n",
      "│ act               �� 'silu'                     │\n",
      "���─���─��───��─────���─────┼──────��─────────────���───────┤\n",
      "│ data_num_workers  │ 4                          │\n",
      "├─��────��────────────┼���────────���───���────────��────��┤\n",
      "│ input_size        ��� (640, 640)                 │\n",
      "├───────��──────────���┼─────────���────���────��────────┤\n",
      "│ multiscale_range  │ 5                          │\n",
      "├───────────��─��───���─┼──────────���─────────────────┤\n",
      "│ data_dir          │ None                       │\n",
      "├��────��─────────────���──────────���──────────���────���─┤\n",
      "│ train_ann         │ 'instances_train2017.json' │\n",
      "├��────���────���────���───��───��────────��────��────���───��─┤\n",
      "│ val_ann           │ 'instances_val2017.json'   │\n",
      "��─────���──────────���──┼─────���───���────��─────���────��──┤\n",
      "│ test_ann          │ 'instances_test2017.json'  │\n",
      "├───���───���────��────��─┼───────────���───────���───��────���\n",
      "│ mosaic_prob       ��� 1.0                        │\n",
      "├��─────────��────────┼────���───────────────��───────┤\n",
      "�� mixup_prob        │ 1.0                        │\n",
      "├───���──────���──────���─┼─────────��──────���──────���────┤\n",
      "│ hsv_prob          �� 1.0                        │\n",
      "├──���──────���──────��──┼───��────��───��─────���────────��┤\n",
      "│ flip_prob         ��� 0.5                        │\n",
      "├─────��───��─────���───┼────────��────���───���─────────��┤\n",
      "│ degrees           │ 10.0                       │\n",
      "��──��───���───���────────┼���────────��───��─��─���───���─��─��──┤\n",
      "│ translate         ��� 0.1                        │\n",
      "���──��─��────────���─��───┼──��────��─────��─��────���──���──��─┤\n",
      "│ mosaic_scale      │ (0.1, 2)                   ���\n",
      "├──────���─��────���─────┼─��─��────���─���─��─��───���──��─���─���─��┤\n",
      "��� enable_mixup      │ True                       │\n",
      "├───��────����───���───���─┼─────��──���─��─��───���──���─────���─���┤\n",
      "│ mixup_scale       │ (0.5, 1.5)                 │\n",
      "├���─�����─��───────��──��─���┼���───────��──��────���─���─��──���──��─┤\n",
      "�� shear             │ 2.0                        │\n",
      "├��────���─���─���─�����─����───┼��─��─────��──���────���─────���────���┤\n",
      "�� warmup_epochs     │ 5                          ���\n",
      "├──���─��────�����─��──���─��─��─��───���──���───���─���─��────────���─�����\n",
      "│ max_epoch         │ 300                        ���\n",
      "���──────���────────────┼───���─���─��───���──��───��─��─────���─┤\n",
      "��� warmup_lr         │ 0                          │\n",
      "├�����─���─���─���──���──��─────���─��──────�����─���─���──���──��─────��─�����\n",
      "�� min_lr_ratio      │ 0.05                       │\n",
      "����─��──����─��──��─����─����─��──����─������─�����────��─�����───��������───���┤\n",
      "│ basic_lr_per_img  �� 0.00015625                 │\n",
      "├─����───���─���─��───�����─��─┼──���─��───�����─────���─��──���─��───���─┤\n",
      "��� scheduler         �� 'yoloxwarmcos'             ���\n",
      "├────���─��─���──��──────���┼─────���──��─��─��─���──��───���──��───┤\n",
      "│ no_aug_epochs     │ 15                         │\n",
      "├���─────��─��──────────┼────���──��───���────���─�����───���───���┤\n",
      "��� ema               │ True                       ���\n",
      "├──���──��──���─────���─��──┼���─���─��─��────────��─��───��───���──┤\n",
      "│ weight_decay      │ 0.0005                     │\n",
      "├��───��───���──────��───┼──��──────��───���──��───���──────���┤\n",
      "│ momentum          │ 0.9                        │\n",
      "���──────��──────��─────┼───��──────��──────��───���──────��\n",
      "│ save_history_ckpt │ True                       │\n",
      "��───��───���───��───���───┼──���──────��──────��───���──��───���┤\n",
      "│ exp_name          │ 'yolox_s'                  ���\n",
      "├─���─��───���──��───���──��─┼─���──��──────────���──────��─────┤\n",
      "��� test_size         │ (640, 640)                 ���\n",
      "├─���───���──────���──────���─────���──��─────���──────���───���──┤\n",
      "│ test_conf         │ 0.01                       │\n",
      "├���──────���──────���────┼��────────────────���──��───���──��┤\n",
      "│ nmsthre           ��� 0.65                       │\n",
      "╘═══���══��══════���══���══��═��════════���═���══��═��════════���═���\n",
      "2024-08-26 16:48:40 | INFO     | yolox.core.trainer:154 - Model Summary: Params: 8.97M, Gflops: 26.93\n",
      "2024-08-26 16:48:40 | INFO     | yolox.data.datasets.coco:63 - loading annotations into memory...\n",
      "2024-08-26 16:48:50 | INFO     | yolox.data.datasets.coco:63 - Done (t=10.62s)\n",
      "2024-08-26 16:48:50 | INFO     | pycocotools.coco:86 - creating index...\n",
      "2024-08-26 16:48:51 | INFO     | pycocotools.coco:86 - index created!\n",
      "2024-08-26 16:49:15 | INFO     | yolox.core.trainer:173 - init prefetcher, this might take one minute or less...\n",
      "2024-08-26 16:49:15 | INFO     | yolox.data.datasets.coco:63 - loading annotations into memory...\n",
      "2024-08-26 16:49:15 | INFO     | yolox.data.datasets.coco:63 - Done (t=0.26s)\n",
      "2024-08-26 16:49:15 | INFO     | pycocotools.coco:86 - creating index...\n",
      "2024-08-26 16:49:15 | INFO     | pycocotools.coco:86 - index created!\n",
      "2024-08-26 16:49:16 | INFO     | yolox.core.trainer:215 - Training start...\n",
      "2024-08-26 16:49:16 | INFO     | yolox.core.trainer:216 - \n",
      "YOLOX(\n",
      "  (backbone): YOLOPAFPN(\n",
      "    (backbone): CSPDarknet(\n",
      "      (stem): Focus(\n",
      "        (conv): BaseConv(\n",
      "          (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (dark2): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark3): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (2): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark4): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (2): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dark5): Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): SPPBottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): ModuleList(\n",
      "            (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "            (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
      "            (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): CSPLayer(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv3): BaseConv(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (conv1): BaseConv(\n",
      "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (conv2): BaseConv(\n",
      "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (lateral_conv0): BaseConv(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_p4): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reduce_conv1): BaseConv(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_p3): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bu_conv2): BaseConv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_n3): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (bu_conv1): BaseConv(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (C3_n4): CSPLayer(\n",
      "      (conv1): BaseConv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv2): BaseConv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (conv3): BaseConv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (conv2): BaseConv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): YOLOXHead(\n",
      "    (cls_convs): ModuleList(\n",
      "      (0-2): 3 x Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reg_convs): ModuleList(\n",
      "      (0-2): 3 x Sequential(\n",
      "        (0): BaseConv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): BaseConv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls_preds): ModuleList(\n",
      "      (0-2): 3 x Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (reg_preds): ModuleList(\n",
      "      (0-2): 3 x Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (obj_preds): ModuleList(\n",
      "      (0-2): 3 x Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (stems): ModuleList(\n",
      "      (0): BaseConv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): BaseConv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): BaseConv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (l1_loss): L1Loss()\n",
      "    (bcewithlog_loss): BCEWithLogitsLoss()\n",
      "    (iou_loss): IOUloss()\n",
      "  )\n",
      ")\n",
      "2024-08-26 16:49:16 | INFO     | yolox.core.trainer:237 - ---> start train epoch1\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX [tensor([[[[ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "          [ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "          [ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "          ...,\n",
      "          [ 25.,  22.,  22.,  ...,  57.,  57.,  57.],\n",
      "          [ 22.,  19.,  21.,  ...,  57.,  57.,  57.],\n",
      "          [ 29.,  24.,  25.,  ...,  57.,  57.,  57.]],\n",
      "\n",
      "         [[ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "          [ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "          [ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "          ...,\n",
      "          [ 56.,  48.,  46.,  ...,  57.,  57.,  57.],\n",
      "          [ 48.,  43.,  44.,  ...,  57.,  57.,  57.],\n",
      "          [ 55.,  49.,  49.,  ...,  57.,  57.,  57.]],\n",
      "\n",
      "         [[ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "          [ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "          [ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "          ...,\n",
      "          [ 53.,  45.,  42.,  ...,  57.,  57.,  57.],\n",
      "          [ 48.,  40.,  41.,  ...,  57.,  57.,  57.],\n",
      "          [ 53.,  46.,  46.,  ...,  57.,  57.,  57.]]],\n",
      "\n",
      "\n",
      "        [[[182., 173., 161.,  ..., 131., 131., 131.],\n",
      "          [184., 177., 163.,  ..., 131., 131., 131.],\n",
      "          [187., 181., 170.,  ..., 131., 131., 131.],\n",
      "          ...,\n",
      "          [ 54.,  59.,  57.,  ..., 131., 131., 131.],\n",
      "          [ 57.,  66.,  61.,  ..., 131., 131., 131.],\n",
      "          [ 49.,  65.,  62.,  ..., 131., 131., 131.]],\n",
      "\n",
      "         [[182., 173., 161.,  ..., 131., 131., 131.],\n",
      "          [184., 177., 163.,  ..., 131., 131., 131.],\n",
      "          [187., 181., 170.,  ..., 131., 131., 131.],\n",
      "          ...,\n",
      "          [ 64.,  69.,  69.,  ..., 131., 131., 131.],\n",
      "          [ 65.,  72.,  70.,  ..., 131., 131., 131.],\n",
      "          [ 56.,  69.,  67.,  ..., 131., 131., 131.]],\n",
      "\n",
      "         [[182., 173., 161.,  ..., 131., 131., 131.],\n",
      "          [184., 177., 163.,  ..., 131., 131., 131.],\n",
      "          [187., 181., 170.,  ..., 131., 131., 131.],\n",
      "          ...,\n",
      "          [ 65.,  72.,  71.,  ..., 131., 131., 131.],\n",
      "          [ 71.,  72.,  72.,  ..., 131., 131., 131.],\n",
      "          [ 59.,  74.,  70.,  ..., 131., 131., 131.]]]]), tensor([[[ 32.0000, 242.1493, 331.1004,  14.5702,  14.8041],\n",
      "         [ 32.0000, 321.9911, 351.1843,  21.2923,   9.1475],\n",
      "         [  0.0000, 330.2680, 338.6593, 162.9839, 430.6814],\n",
      "         ...,\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[ 46.0000, 182.4230, 299.0594, 364.8460, 165.7585],\n",
      "         [ 22.0000, 156.5014, 635.7900,  58.5737,   8.4200],\n",
      "         [ 22.0000,  71.9726, 631.9395, 124.8910,  16.1210],\n",
      "         ...,\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]]), [tensor([640, 640]), tensor([3, 3])], tensor([[126489],\n",
      "        [186368]])]\n",
      "111111111111111111111111111XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX 4\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Grid Size = torch.Size([1])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Batch Size = 2\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX output_size = torch.Size([2, 85, 80, 80])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX DType is = torch.xla.FloatTensor\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Shape after stack is = torch.Size([80, 80, 2])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Shape after stack is = torch.int64\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Grid Size = torch.Size([1])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Batch Size = 2\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX output_size = torch.Size([2, 85, 40, 40])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX DType is = torch.xla.FloatTensor\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Shape after stack is = torch.Size([40, 40, 2])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Shape after stack is = torch.int64\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Grid Size = torch.Size([1])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Batch Size = 2\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX output_size = torch.Size([2, 85, 20, 20])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX DType is = torch.xla.FloatTensor\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Shape after stack is = torch.Size([20, 20, 2])\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Shape after stack is = torch.int64\n",
      "2024-08-26 16:49:17.000164:  20428  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-26 16:49:17.000164:  20428  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_11790936170214357810+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-26 16:49:17.000171:  20428  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-26 16:49:17.000171:  20428  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_494008848328720989+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX TL Type = torch.xla.FloatTensor\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX BR Type = torch.xla.FloatTensor\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX output_size = torch.xla.BoolTensor\n",
      "2024-08-26 16:49:17.000176:  20428  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-26 16:49:17.000177:  20428  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_1679001686750454521+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-26 16:49:17.000178:  20428  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-26 16:49:17.000179:  20428  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_3620515100852396713+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-26 16:49:17 | ERROR    | yolox.core.trainer:89 - Exception in training: \n",
      "2024-08-26 16:49:17 | INFO     | yolox.core.trainer:219 - Training of experiment is done and the best AP is 0.00\n",
      "2024-08-26 16:49:17.000349:  20428  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-26 16:49:17.000349:  20428  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_3941120121036684346+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-26 16:49:17.000395:  20428  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-26 16:49:17.000395:  20428  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_15457411607563270555+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-26 16:49:17.000444:  20428  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-26 16:49:17.000444:  20428  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_18058599337860878096+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-26 16:49:17.000484:  20428  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-26 16:49:17.000485:  20428  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_12252831604813668132+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-26 16:49:17.000487:  20428  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-26 16:49:17.000488:  20428  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_6427028763540755556+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-26 16:49:17.000535:  20428  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-26 16:49:17.000536:  20428  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_9075833724348365907+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-26 16:49:17.000557:  20428  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-26 16:49:17.000558:  20428  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_3288600609627781372+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-26 16:49:17.000605:  20428  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-26 16:49:17.000606:  20428  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_1219469151892255121+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-26 16:49:17.000674:  20428  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-26 16:49:17.000675:  20428  INFO ||NEURON_CC_WRAPPER||: Extracting graphs (/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_610965070153050574+ade7b014/model.hlo_module.pb) for ahead-of-time parallel compilation. No compilation was done.\n",
      "2024-08-26 16:49:17 | ERROR    | yolox.core.launch:98 - An error has been caught in function 'launch', process 'MainProcess' (20428), thread 'MainThread' (140543937684096):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "           │         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'yolox.tools', '__loader__': <_frozen_importlib_external.SourceFileL...\n",
      "           │         └ <code object <module> at 0x7fd2ef1149d0, file \"/home/ubuntu/neuron-adoption/tools/train.py\", line 1>\n",
      "           └ <function _run_code at 0x7fd2ef10d2d0>\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "         │     └ {'__name__': '__main__', '__doc__': None, '__package__': 'yolox.tools', '__loader__': <_frozen_importlib_external.SourceFileL...\n",
      "         �� <code object <module> at 0x7fd2ef1149d0, file \"/home/ubuntu/neuron-adoption/tools/train.py\", line 1>\n",
      "\n",
      "  File \"/home/ubuntu/neuron-adoption/tools/train.py\", line 138, in <module>\n",
      "    launch(\n",
      "    └ <function launch at 0x7fd22e77cd30>\n",
      "\n",
      "> File \"/home/ubuntu/neuron-adoption/yolox/core/launch.py\", line 98, in launch\n",
      "    main_func(*args)\n",
      "    │          └ (╒══��═══════════════���╤═══��═══════���════��══════════���════���════���════��════��══════════���════��════��════��═══════════════���════���════��═══...\n",
      "    └ <function main at 0x7fd22088acb0>\n",
      "\n",
      "  File \"/home/ubuntu/neuron-adoption/tools/train.py\", line 118, in main\n",
      "    trainer.train()\n",
      "    │       └ <function Trainer.train at 0x7fd1ea7e8790>\n",
      "    └ <yolox.core.trainer.Trainer object at 0x7fd1ea7f4490>\n",
      "\n",
      "  File \"/home/ubuntu/neuron-adoption/yolox/core/trainer.py\", line 87, in train\n",
      "    self.train_in_epoch()\n",
      "    │    └ <function Trainer.train_in_epoch at 0x7fd1ea7e9000>\n",
      "    └ <yolox.core.trainer.Trainer object at 0x7fd1ea7f4490>\n",
      "\n",
      "  File \"/home/ubuntu/neuron-adoption/yolox/core/trainer.py\", line 97, in train_in_epoch\n",
      "    self.train_in_iter()\n",
      "    │    └ <function Trainer.train_in_iter at 0x7fd1ea7e9090>\n",
      "    └ <yolox.core.trainer.Trainer object at 0x7fd1ea7f4490>\n",
      "\n",
      "  File \"/home/ubuntu/neuron-adoption/yolox/core/trainer.py\", line 104, in train_in_iter\n",
      "    self.train_one_iter()\n",
      "    │    └ <function Trainer.train_one_iter at 0x7fd1ea7e9120>\n",
      "    └ <yolox.core.trainer.Trainer object at 0x7fd1ea7f4490>\n",
      "\n",
      "  File \"/home/ubuntu/neuron-adoption/yolox/core/trainer.py\", line 123, in train_one_iter\n",
      "    outputs = self.model(inps, targets)\n",
      "              │    │     │     �� tensor([[[ 32.0000, 242.1493, 331.1004,  14.5702,  14.8041],\n",
      "              │    │     │                [ 32.0000, 321.9911, 351.1843,  21.2923,   9.1475],\n",
      "              ���    │     │          ...\n",
      "              │    ���     └ tensor([[[[ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "              ���    │                 [ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "              │    │                 [ 57., ...\n",
      "              │    └ YOLOX(\n",
      "              │        (backbone): YOLOPAFPN(\n",
      "              │          (backbone): CSPDarknet(\n",
      "              │            (stem): Focus(\n",
      "              │              (conv): BaseConv(\n",
      "              │                (conv): ...\n",
      "              └ <yolox.core.trainer.Trainer object at 0x7fd1ea7f4490>\n",
      "\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_2_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           │    ���           │       └ {}\n",
      "           │    │           └ (tensor([[[[ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "           │    │                       [ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "           │    │                       [ 57.,...\n",
      "           │    └ <function Module._call_impl at 0x7fd242f85120>\n",
      "           └ YOLOX(\n",
      "               (backbone): YOLOPAFPN(\n",
      "                 (backbone): CSPDarknet(\n",
      "                   (stem): Focus(\n",
      "                     (conv): BaseConv(\n",
      "                       (conv): ...\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_2_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           │             │       └ {}\n",
      "           │             └ (tensor([[[[ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "           │                         [ 57.,  57.,  57.,  ..., 114., 114., 114.],\n",
      "           │                         [ 57.,...\n",
      "           └ <bound method YOLOX.forward of YOLOX(\n",
      "               (backbone): YOLOPAFPN(\n",
      "                 (backbone): CSPDarknet(\n",
      "                   (stem): Focus(\n",
      "                     (conv...\n",
      "\n",
      "  File \"/home/ubuntu/neuron-adoption/yolox/models/yolox.py\", line 34, in forward\n",
      "    loss, iou_loss, conf_loss, cls_loss, l1_loss, num_fg = self.head(\n",
      "                                                           └ YOLOX(\n",
      "                                                               (backbone): YOLOPAFPN(\n",
      "                                                                 (backbone): CSPDarknet(\n",
      "                                                                   (stem): Focus(\n",
      "                                                                     (conv): BaseConv(\n",
      "                                                                       (conv): ...\n",
      "\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_2_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           │    │           ��       └ {}\n",
      "           │    │           ��� ((tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           │    │                       [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           │    │                       [0., 0., 0.,  ..., 0., 0., 0....\n",
      "           │    └ <function Module._call_impl at 0x7fd242f85120>\n",
      "           └ YOLOXHead(\n",
      "               (cls_convs): ModuleList(\n",
      "                 (0-2): 3 x Sequential(\n",
      "                   (0): BaseConv(\n",
      "                     (conv): Conv2d(128, 128, kernel...\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_2_1/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           │             │       └ {}\n",
      "           │             └ ((tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           │                         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ��                         [0., 0., 0.,  ..., 0., 0., 0....\n",
      "           └ <bound method YOLOXHead.forward of YOLOXHead(\n",
      "               (cls_convs): ModuleList(\n",
      "                 (0-2): 3 x Sequential(\n",
      "                   (0): BaseConv(\n",
      "                 ...\n",
      "\n",
      "  File \"/home/ubuntu/neuron-adoption/yolox/models/yolo_head.py\", line 194, in forward\n",
      "    return self.get_losses(\n",
      "           │    └ <function YOLOXHead.get_losses at 0x7fd1ea80f490>\n",
      "           └ YOLOXHead(\n",
      "               (cls_convs): ModuleList(\n",
      "                 (0-2): 3 x Sequential(\n",
      "                   (0): BaseConv(\n",
      "                     (conv): Conv2d(128, 128, kernel...\n",
      "\n",
      "  File \"/home/ubuntu/neuron-adoption/yolox/models/yolo_head.py\", line 332, in get_losses\n",
      "    ) = self.get_assignments(  # noqa\n",
      "        │    └ <function YOLOXHead.get_assignments at 0x7fd1ea80f640>\n",
      "        └ YOLOXHead(\n",
      "            (cls_convs): ModuleList(\n",
      "              (0-2): 3 x Sequential(\n",
      "                (0): BaseConv(\n",
      "                  (conv): Conv2d(128, 128, kernel...\n",
      "\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_2_1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ���     │       └ {}\n",
      "           │     └ (YOLOXHead(\n",
      "           │         (cls_convs): ModuleList(\n",
      "           │           (0-2): 3 x Sequential(\n",
      "           │             (0): BaseConv(\n",
      "           │               (conv): Conv2d(128, 128, kerne...\n",
      "           └ <function YOLOXHead.get_assignments at 0x7fd1ea80f5b0>\n",
      "\n",
      "  File \"/home/ubuntu/neuron-adoption/yolox/models/yolo_head.py\", line 501, in get_assignments\n",
      "    cls_preds_.unsqueeze(0).repeat(num_gt, 1, 1),\n",
      "    │          │                   └ 4593671620974870528\n",
      "    │          └ <method 'unsqueeze' of 'torch._C._TensorBase' objects>\n",
      "    ��� tensor([], device='xla:0', size=(0, 80))\n",
      "\n",
      "RuntimeError: The operator aten::as_strided appears to be a view operator, but it has no implementation for the backend \"xla:0\". View operators don't support since the tensor's storage cannot be shared across devices.\n",
      "2024-08-26 16:49:22.000253:  20405  INFO ||NEURON_PARALLEL_COMPILE||: New graph list from script 13: /home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_11790936170214357810+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_494008848328720989+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_1679001686750454521+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_3620515100852396713+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_3941120121036684346+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_15457411607563270555+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_18058599337860878096+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_12252831604813668132+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_6427028763540755556+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_9075833724348365907+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_3288600609627781372+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_1219469151892255121+ade7b014/model.hlo_module.pb\n",
      "\t/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_610965070153050574+ade7b014/model.hlo_module.pb\n",
      "2024-08-26 16:49:22.000253:  20405  INFO ||NEURON_CACHE||: Compile cache path: ./compiler_cache\n",
      "2024-08-26 16:49:22.000285:  20741  INFO ||NEURON_PARALLEL_COMPILE||: worker 0 starts dynamic scheduleing on 13....\n",
      "2024-08-26 16:49:22.000285:  20742  INFO ||NEURON_PARALLEL_COMPILE||: worker 1 starts dynamic scheduleing on 13....\n",
      "2024-08-26 16:49:22.000285:  20743  INFO ||NEURON_PARALLEL_COMPILE||: worker 2 starts dynamic scheduleing on 13....\n",
      "2024-08-26 16:49:22.000285:  20744  INFO ||NEURON_PARALLEL_COMPILE||: worker 3 starts dynamic scheduleing on 13....\n",
      "2024-08-26 16:49:22.000285:  20745  INFO ||NEURON_PARALLEL_COMPILE||: worker 4 starts dynamic scheduleing on 13....\n",
      "2024-08-26 16:49:22.000285:  20746  INFO ||NEURON_PARALLEL_COMPILE||: worker 5 starts dynamic scheduleing on 13....\n",
      "2024-08-26 16:49:22.000285:  20747  INFO ||NEURON_PARALLEL_COMPILE||: worker 6 starts dynamic scheduleing on 13....\n",
      "2024-08-26 16:49:22.000286:  20748  INFO ||NEURON_PARALLEL_COMPILE||: worker 7 starts dynamic scheduleing on 13....\n",
      "2024-08-26 16:49:22.000286:  20746  INFO ||NEURON_PARALLEL_COMPILE||: worker 5 finished with num of tasks 0....\n",
      "2024-08-26 16:49:22.000286:  20745  INFO ||NEURON_PARALLEL_COMPILE||: worker 4 finished with num of tasks 0....\n",
      "2024-08-26 16:49:22.000286:  20747  INFO ||NEURON_PARALLEL_COMPILE||: worker 6 finished with num of tasks 0....\n",
      "2024-08-26 16:49:22.000286:  20748  INFO ||NEURON_PARALLEL_COMPILE||: worker 7 finished with num of tasks 0....\n",
      "2024-08-26 16:49:22.000286:  20743  INFO ||NEURON_PARALLEL_COMPILE||: worker 2 finished with num of tasks 0....\n",
      "2024-08-26 16:49:22.000286:  20744  INFO ||NEURON_PARALLEL_COMPILE||: worker 3 finished with num of tasks 0....\n",
      "2024-08-26 16:49:22.000287:  20746  INFO ||NEURON_CACHE||: Current remaining items are 0, locked are 2, failed are 0, done are 16, total is 18\n",
      "2024-08-26 16:49:22.000287:  20747  INFO ||NEURON_CACHE||: Current remaining items are 0, locked are 2, failed are 0, done are 16, total is 18\n",
      "2024-08-26 16:49:22.000287:  20745  INFO ||NEURON_CACHE||: Current remaining items are 0, locked are 2, failed are 0, done are 16, total is 18\n",
      "2024-08-26 16:49:22.000287:  20748  INFO ||NEURON_CACHE||: Current remaining items are 0, locked are 2, failed are 0, done are 16, total is 18\n",
      "2024-08-26 16:49:22.000287:  20743  INFO ||NEURON_CACHE||: Current remaining items are 0, locked are 2, failed are 0, done are 16, total is 18\n",
      "2024-08-26 16:49:22.000287:  20744  INFO ||NEURON_CACHE||: Current remaining items are 0, locked are 2, failed are 0, done are 16, total is 18\n",
      "2024-08-26 16:49:22.000287:  20741  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/67e22a64-15f6-45b7-ace4-0822b58e786c/model.MODULE_1679001686750454521+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/67e22a64-15f6-45b7-ace4-0822b58e786c/model.MODULE_1679001686750454521+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "2024-08-26 16:49:22.000288:  20742  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/7a0c8732-0d61-4059-a46a-ddc1a4a9ac77/model.MODULE_3620515100852396713+ade7b014.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/7a0c8732-0d61-4059-a46a-ddc1a4a9ac77/model.MODULE_3620515100852396713+ade7b014.neff --model-type=cnn-training --verbose=35\n",
      "..\n",
      "Compiler status PASS\n",
      "\n",
      "Compiler status PASS\n",
      "2024-08-26 16:49:24.000306:  20742  INFO ||NEURON_PARALLEL_COMPILE||: worker 1 finished with num of tasks 1....\n",
      "2024-08-26 16:49:24.000307:  20742  INFO ||NEURON_CACHE||: Current remaining items are 0, locked are 1, failed are 0, done are 17, total is 18\n",
      "2024-08-26 16:49:24.000320:  20741  INFO ||NEURON_PARALLEL_COMPILE||: worker 0 finished with num of tasks 1....\n",
      "2024-08-26 16:49:24.000320:  20741  INFO ||NEURON_CACHE||: Current remaining items are 0, locked are 0, failed are 0, done are 18, total is 18\n",
      "2024-08-26 16:49:24.000333:  20405  INFO ||NEURON_PARALLEL_COMPILE||: {\n",
      "    \"compilation_summary\": {\n",
      "        \"true\": 2\n",
      "    },\n",
      "    \"compilation_report\": {\n",
      "        \"/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_1679001686750454521+ade7b014/model.hlo_module.pb\": {\n",
      "            \"status\": true,\n",
      "            \"retry\": 0,\n",
      "            \"compile_time\": 2.0335206985473633\n",
      "        },\n",
      "        \"/home/ubuntu/neuron-adoption/compiler_cache/neuronxcc-2.14.227.0+2d4f85be/MODULE_3620515100852396713+ade7b014/model.hlo_module.pb\": {\n",
      "            \"status\": true,\n",
      "            \"retry\": 0,\n",
      "            \"compile_time\": 2.0200583934783936\n",
      "        }\n",
      "    },\n",
      "    \"start_time\": 1724690962.2538002,\n",
      "    \"compilation_time\": 2.079958915710449\n",
      "}\n",
      "2024-08-26 16:49:24.000333:  20405  INFO ||NEURON_PARALLEL_COMPILE||: Total graphs: 2\n",
      "2024-08-26 16:49:24.000333:  20405  INFO ||NEURON_PARALLEL_COMPILE||: Total successful compilations: 2\n",
      "2024-08-26 16:49:24.000333:  20405  INFO ||NEURON_PARALLEL_COMPILE||: Total failed compilations: 0\n",
      "Compilation Success!!!\n",
      "CPU times: user 28.1 ms, sys: 25.2 ms, total: 53.3 ms\n",
      "Wall time: 58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import subprocess\n",
    "print(\"Compile model\")\n",
    "COMPILE_CMD = f\"\"\"{env_var_options} neuron_parallel_compile python -m \\\n",
    "   yolox.tools.train \\\n",
    "    -n {model} \\\n",
    "    -d {num_accelerators} \\\n",
    "    -b {total_batch_size} \\\n",
    "    \"\"\"\n",
    "\n",
    "print(f'Running command: \\n{COMPILE_CMD}')\n",
    "if subprocess.check_call(COMPILE_CMD,shell=True):\n",
    "   print(\"There was an error with the compilation command\")\n",
    "else:\n",
    "   print(\"Compilation Success!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "071f7b26-b224-4538-bd6c-6a3d323686d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_xla.distributed.xla_backend\n",
    "import torch_xla\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d880e4b8-38d3-458c-994c-a7fbb1631533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23705c52-b381-4b5d-8b89-d66fac678cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = xm.xla_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "348aadb9-82d5-43d4-be83-68c8dd8c66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tens = torch_xla.torch.tensor([[[1,1,1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7999adb-2dc5-4b8a-9b60-a79aac014c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a3a6859-27dd-4ab8-82c6-07c40fba9cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tens = n_tens.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6da471de-941d-460b-8443-6116579fc5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.xla.LongTensor'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((n_tens, n_tens), 2).view(1,2,1,3).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4173a228-4eae-4740-ba2c-493202cad341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-26 16:47:32.000558:  17656  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-08-26 16:47:32.000560:  17656  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/1f02e8d0-4c69-4361-b943-a91ce88f09d3/model.MODULE_16302122862933890670+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/1f02e8d0-4c69-4361-b943-a91ce88f09d3/model.MODULE_16302122862933890670+d41d8cd9.neff --verbose=35\n",
      ".\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0]], device='xla:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(n_tens < n_tens).type_as(n_tens).prod(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d0d7706-047b-4b5a-92a8-cb24213f65e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-26 14:58:45.000366:  13842  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-08-26 14:58:45.000369:  13842  INFO ||NEURON_CC_WRAPPER||: Call compiler with cmd: neuronx-cc compile --target=trn1 --framework=XLA /tmp/ubuntu/neuroncc_compile_workdir/e684824e-fb48-467c-852b-e3ad912eb2a2/model.MODULE_11410224952559862343+d41d8cd9.hlo_module.pb --output /tmp/ubuntu/neuroncc_compile_workdir/e684824e-fb48-467c-852b-e3ad912eb2a2/model.MODULE_11410224952559862343+d41d8cd9.neff --verbose=35\n",
      ".\n",
      "Compiler status PASS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False]]], device='xla:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(n_tens < n_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83b59796-0a46-4a38-8252-fbe180a9c834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.xla.BoolTensor'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(n_tens < n_tens).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dbfbb2-406a-4088-9ab5-19b50767f1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "174a16e1-15b2-4d13-b767-c71b6450ecd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch_xla' has no attribute 'FloatTensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (n_tens \u001b[38;5;241m<\u001b[39m n_tens)\u001b[38;5;241m.\u001b[39mtype(dtype\u001b[38;5;241m=\u001b[39m\u001b[43mtorch_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch_xla' has no attribute 'FloatTensor'"
     ]
    }
   ],
   "source": [
    "(n_tens < n_tens).type(dtype=torch_xla.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af46082d-b9b8-4c24-b079-eb2d4ada5ab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid type: 'torch.xla.LongTensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m(\u001b[49m\u001b[43mn_tens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_tens\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorch.xla.LongTensor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid type: 'torch.xla.LongTensor'"
     ]
    }
   ],
   "source": [
    "(n_tens < n_tens).type(\"torch.xla.LongTensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c306f8d1-3d40-46b4-ad6a-95e7efbc9760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2b5a5a6-3590-4e75-8f33-d7f1f310dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,1,1,]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f92b7e-70d5-4f6c-9b34-fb9f2ffaea6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a > a).type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc1a40-a47c-4a56-b4f2-524da1407c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
